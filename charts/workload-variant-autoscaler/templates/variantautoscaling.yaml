{{- if .Values.va.enabled }}
apiVersion: llmd.ai/v1alpha1
# Optimizing a variant, create only when the model is deployed and serving traffic
# this is for the collector the collect existing (previous) running metrics of the variant.
kind: VariantAutoscaling
metadata:
  # Unique name of the variant (includes release name for multi-install support)
  name: {{ include "workload-variant-autoscaler.fullname" . }}-va
  namespace: {{ .Values.llmd.namespace }}
  labels:
    {{- include "workload-variant-autoscaler.labels" . | nindent 4 }}
    inference.optimization/acceleratorName: {{ .Values.va.accelerator }}
    {{- if .Values.wva.controllerInstance }}
    wva.llmd.ai/controller-instance: {{ .Values.wva.controllerInstance | quote }}
    {{- end }}
# This is essentially static input to the optimizer
spec:
  # ScaleTargetRef references the target resource to scale (similar to HPA)
  # TODO: Support templating for scaleTargetRef to enable managing groups of deployments
  scaleTargetRef:
    kind: Deployment
    name: {{ .Values.llmd.deploymentName | default (printf "%s-decode" .Values.llmd.modelName) }}
  # OpenAI API compatible name of the model
  modelID: {{ .Values.llmd.modelID | quote }}
  # Cost per replica for this variant (used in saturation analysis)
  variantCost: {{ .Values.va.variantCost | default "10.0" | quote }}
{{- end }}